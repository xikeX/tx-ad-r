def train_embedding_model(embedding_model:EmbeddingModel, train_loader, valid_loader, optimizer, args, writer, log_file, global_step,verbose = False):
    """è®­ç»ƒåµŒå…¥æ¨¡å‹ä¸»å¾ªç¯"""
    print("å¼€å§‹è®­ç»ƒåµŒå…¥æ¨¡å‹...")
    bce_criterion = nn.BCEWithLogitsLoss(reduction='mean')
    best_val_loss = float('inf')
    # è®¾ç½®ç­–ç•¥warmup å’Œ cosine decayç­–ç•¥
    scheduler=None
    if args.use_lr_scheduler_in_embedding_task:
        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(args.warm_up_rate * len(train_loader)),
                                                num_training_steps=args.num_epochs * len(train_loader))
    for epoch in range(1, args.num_epochs + 1):
        embedding_model.train()
        if args.inference_only:
            print("inference_only æ¨¡å¼å¼€å¯ï¼Œè·³è¿‡è®­ç»ƒã€‚")
            break

        t0 = time.time()
        total_loss_epoch = 0.0

        # å¯ç”¨æ¢¯åº¦ç¼©æ”¾ï¼ˆç”¨äºæ··åˆç²¾åº¦æˆ–é˜²æ­¢æº¢å‡ºï¼‰
        scaler = torch.cuda.amp.GradScaler() if args.device == 'cuda' else None
        local_step = 0
        with tqdm(train_loader,total=-1, desc=f"Epoch {epoch}", leave=False) as pbar:
            for step, batch in enumerate(pbar):
                try:
                    # è§£åŒ…æ•°æ®
                    user, input_item, pos_item, neg_item, \
                    user_feat, input_item_feat, pos_item_feat, neg_item_feat = batch

                    # ======== å‰å‘ä¼ æ’­ï¼ˆä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦å¯é€‰ï¼‰========
                    if scaler:
                        with torch.cuda.amp.autocast():
                            user_embedding = embedding_model(user,user_feat).squeeze(0)
                            item_1_embedding = embedding_model(input_item,input_item_feat).squeeze(0)
                            pos_item_embedding = embedding_model(pos_item,pos_item_feat).squeeze(0)
                            neg_item_1_embedding = embedding_model(neg_item,neg_item_feat).squeeze(0)
                            neg_item_2_embedding = embedding_model(neg_item,neg_item_feat).squeeze(0)
                            u2i_loss,u2i_pos_sim,u2i_neg_sim = embedding_model.embedding_loss(user_embedding,item_1_embedding,neg_item_1_embedding)
                            i2i_loss,i2i_pos_sim,i2i_neg_sim = embedding_model.embedding_loss(item_1_embedding,pos_item_embedding,neg_item_2_embedding)
                            self_i2i_loss,i2i_pos_sim,i2i_neg_sim = embedding_model.embedding_loss(neg_item_1_embedding.reshape(-1,neg_item_1_embedding.shape[-1]),neg_item_1_embedding.reshape(-1,neg_item_1_embedding.shape[-1]))
                            loss = u2i_loss + i2i_loss 
                    else:
                        user_embedding = embedding_model(user,user_feat).squeeze(0)
                        item_1_embedding = embedding_model(input_item,input_item_feat).squeeze(0)
                        pos_item_embedding = embedding_model(pos_item,pos_item_feat).squeeze(0)
                        neg_item_1_embedding = embedding_model(neg_item,neg_item_feat).squeeze(0)
                        # neg_item_2_embedding = embedding_model(neg_item,neg_item_feat).squeeze(0)
                        u2i_loss,u2i_pos_sim,u2i_neg_sim = embedding_model.embedding_loss(user_embedding,item_1_embedding,neg_item_1_embedding)
                        i2i_loss,i2i_pos_sim,i2i_neg_sim = embedding_model.embedding_loss(item_1_embedding,pos_item_embedding,neg_item_1_embedding)
                        self_i2i_loss,i2i_pos_sim,i2i_neg_sim = embedding_model.embedding_loss(neg_item_1_embedding.reshape(-1,neg_item_1_embedding.shape[-1]),neg_item_1_embedding.reshape(-1,neg_item_1_embedding.shape[-1]))
                        loss = u2i_loss + i2i_loss 

                        # L2 æ­£åˆ™åŒ–ï¼šä»…ä½œç”¨äº item_embï¼Œé¿å…è¿‡å¼ºæƒ©ç½š
                        if args.l2_emb > 0:
                            l2_reg = 0.0
                            for param in embedding_model.item_emb.parameters():
                                l2_reg += torch.norm(param)
                            loss += args.l2_emb * l2_reg

                    # ======== åå‘ä¼ æ’­ ========
                    optimizer.zero_grad()
                    local_step +=1
                    if scaler is not None:
                        # æ··åˆç²¾åº¦åå‘ä¼ æ’­
                        scaler.scale(loss).backward()
                        # æ¢¯åº¦è£å‰ªï¼ˆåœ¨ unscale ä¹‹åï¼‰
                        scaler.unscale_(optimizer)
                        clip_grad_norm_(embedding_model.parameters(), max_norm=1.0)
                        scaler.step(optimizer)
                        scaler.update()
                    else:
                        # æ™®é€šç²¾åº¦
                        loss.backward()
                        clip_grad_norm_(embedding_model.parameters(), max_norm=1.0)
                        optimizer.step()

                    # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
                    if scheduler is not None:
                        scheduler.step()

                    # ======== æ—¥å¿—è®°å½• ========
                    total_loss_epoch += loss.item()

                    # å½“å‰å­¦ä¹ ç‡
                    current_lr = scheduler.get_last_lr()[0] if scheduler is not None else args.embedding_task_lr

                    log_json = json.dumps({
                        'global_step': global_step,
                        'total_loss': round(loss.item(), 6),
                        'u2i_loss': round(u2i_loss.item(), 6),
                        "i2i_loss": round(i2i_loss.item(), 6),
                        'learning_rate': round(current_lr, 8),
                        'epoch': epoch,
                        'time': time.time()
                    })
                    log_file.write(log_json + '\n')
                    if verbose:
                        print(log_json)
                    log_file.flush()

                    writer.add_scalar('Emd_Loss/total_loss', loss.item(), global_step)
                    writer.add_scalar('Emd_Loss/u2i_loss', u2i_loss.item(), global_step)
                    writer.add_scalar('Emd_Loss/i2i_loss', i2i_loss.item(), global_step)
                    writer.add_scalar('Emd_Loss/self_i2i_loss', self_i2i_loss.item(), global_step)
                    writer.add_scalar('Emd_Loss/Learning_rate', current_lr, global_step)

                    global_step += 1
                    pbar.set_postfix({'loss': f'{loss.item():.4f}', 'lr': f'{current_lr:.2e}'})
                except Exception as e:
                    print(f"\nâŒ Error at epoch {epoch}, step {step}: {str(e)}")
                    # å¯é€‰ï¼šä¿å­˜å½“å‰ batch æ•°æ®ç”¨äº debug
                    # torch.save(batch, "debug_batch.pt")
                    raise  #    


        avg_train_loss = total_loss_epoch / local_step
        print(f"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Time: {time.time() - t0:.2f}s")

        # éªŒè¯é˜¶æ®µ
        embedding_model.eval()
        val_loss = 0.0
        val_ui2_loss = 0.0
        val_i2i_loss = 0.0
        val_self_i2i_loss = 0.0
        vel_local_step = 0
        with torch.no_grad():
            for batch in tqdm(valid_loader, total=-1, desc="Validation", leave=True):
                user, input_item, pos_item, neg_item, \
                user_feat, input_item_feat, pos_item_feat, neg_item_feat = batch

                user_embedding = embedding_model(user,user_feat).squeeze(0)
                item_1_embedding = embedding_model(input_item,input_item_feat).squeeze(0)
                pos_item_embedding = embedding_model(pos_item,pos_item_feat).squeeze(0)
                neg_item_1_embedding = embedding_model(neg_item,neg_item_feat).squeeze(0)
                neg_item_2_embedding = embedding_model(neg_item,neg_item_feat).squeeze(0)
                u2i_loss,u2i_pos_sim,u2i_neg_sim = embedding_model.embedding_loss(user_embedding,item_1_embedding,neg_item_1_embedding)
                i2i_loss,i2i_pos_sim,i2i_neg_sim = embedding_model.embedding_loss(item_1_embedding,pos_item_embedding,neg_item_1_embedding)
                self_i2i_loss,i2i_pos_sim,i2i_neg_sim = embedding_model.embedding_loss(neg_item_1_embedding.reshape(-1,neg_item_1_embedding.shape[-1]),neg_item_1_embedding.reshape(-1,neg_item_1_embedding.shape[-1]))
                loss = u2i_loss + i2i_loss 

                val_loss += loss.item()
                val_ui2_loss += u2i_loss.item()
                val_i2i_loss += i2i_loss.item()
                val_self_i2i_loss += self_i2i_loss.item()
                vel_local_step += 1

        val_loss /= vel_local_step
        val_ui2_loss /= vel_local_step
        val_i2i_loss /= vel_local_step
        val_self_i2i_loss /= vel_local_step
        writer.add_scalar('Emb_Valid/Loss', val_loss, global_step)
        writer.add_scalar('Emb_Valid/u2i_loss', val_ui2_loss, global_step)
        writer.add_scalar('Emb_Valid/i2i_loss', val_i2i_loss, global_step)
        writer.add_scalar('Emb_Valid/self_i2i_loss', val_self_i2i_loss, global_step)
        print(f"Epoch {epoch} | Emb_Valid Loss: {val_loss:.4f}")

        if val_loss < best_val_loss:
            best_val_loss = val_loss
            save_dir = Path(os.environ.get('USER_CACHE_PATH')) / "global_best_embedding_model"
            save_dir.mkdir(parents=True, exist_ok=True)
            torch.save(embedding_model.state_dict(), save_dir / "model.pt")
            print(f"âœ… æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³: {save_dir / 'model.pt'}")

    return global_step


def run_embedding_training(
        args,
        train_emb_dataset,
        valid_emb_dataset,
        writer: SummaryWriter,
        log_file,
        final_save_dir,
        device=None
    ):
    """
    å°è£…åµŒå…¥æ¨¡å‹çš„å®Œæ•´è®­ç»ƒæµç¨‹ï¼šåˆå§‹åŒ–ã€åŠ è½½æƒé‡ã€è®­ç»ƒã€ä¿å­˜ã€‚

    Args:
        args: è®­ç»ƒå‚æ•°å‘½åç©ºé—´ï¼Œéœ€åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
            - batch_size
            - lr
            - state_dict_path (å¯é€‰)
            - USER_CACHE_PATH
            - å…¶ä»–æ¨¡å‹ç›¸å…³å‚æ•°
        train_emb_dataset: è®­ç»ƒæ•°æ®é›†ï¼Œéœ€æœ‰ collate_fn
        valid_emb_dataset: éªŒè¯æ•°æ®é›†ï¼Œéœ€æœ‰ collate_fn
        writer: TensorBoard SummaryWriter å®ä¾‹
        log_file: æ—¥å¿—æ–‡ä»¶å¯¹è±¡ï¼ˆå·²æ‰“å¼€ï¼‰
        device: è®­ç»ƒè®¾å¤‡ (å¦‚ 'cuda' æˆ– 'cpu')

    Returns:
        embedding_model: è®­ç»ƒå®Œæˆçš„æ¨¡å‹
        global_step: æ€»è®­ç»ƒæ­¥æ•°
    """
    print("ğŸš€ å¼€å§‹æ„å»ºåµŒå…¥æ¨¡å‹è®­ç»ƒæµç¨‹...")

    # ==========================
    # 1. æ•°æ®åŠ è½½å™¨
    # ==========================
    train_loader = DataLoader(
        train_emb_dataset,
        batch_size=args.embedding_batch_size,
        collate_fn=train_emb_dataset.collate_fn,
        shuffle=False,  # ç¡®ä¿è®­ç»ƒé›†æ‰“ä¹±
    )

    valid_loader = DataLoader(
        valid_emb_dataset,
        batch_size=args.batch_size,
        collate_fn=valid_emb_dataset.collate_fn,
        shuffle=False,
    )

    print(f"ğŸ“Š è®­ç»ƒé›† batch æ•°: {len(train_loader.dataset.sample_index)}, éªŒè¯é›† batch æ•°: {len(valid_loader.dataset.sample_index)}")

    # ==========================
    # 2. æ¨¡å‹åˆå§‹åŒ–
    # ==========================
    embedding_model = EmbeddingModel(
        user_num=train_emb_dataset.base_dataset.usernum,
        item_num=train_emb_dataset.base_dataset.itemnum,
        feat_statistics=train_emb_dataset.base_dataset.feat_statistics,
        feat_types=train_emb_dataset.base_dataset.feature_types,
        args=args
    ).to(args.device)

    # è‡ªå®šä¹‰åˆå§‹åŒ–
    initialize_model_weights(embedding_model)
    print("âœ… æ¨¡å‹æƒé‡å·²åˆå§‹åŒ–")

    # ==========================
    # 3. åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¯é€‰ï¼‰
    # ==========================
    if args.state_dict_path:
        try:
            state_dict = torch.load(args.state_dict_path, map_location=args.device)
            embedding_model.load_state_dict(state_dict)
            print(f"âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒæƒé‡: {args.state_dict_path}")
            log_file.write(f"INFO: Loaded pretrained weights from {args.state_dict_path}\n")
        except Exception as e:
            msg = f"âŒ åŠ è½½é¢„è®­ç»ƒæƒé‡å¤±è´¥: {args.state_dict_path}, é”™è¯¯: {str(e)}"
            print(msg)
            log_file.write(f"ERROR: {msg}\n")
            raise RuntimeError(msg)

    # ==========================
    # 4. ä¼˜åŒ–å™¨
    # ==========================
    optimizer = torch.optim.Adam(
        embedding_model.parameters(),
        lr=args.embedding_task_lr,
        betas=(0.9, 0.98),
        weight_decay=getattr(args, 'weight_decay', 0.0)  # å¯é€‰ weight decay
    )

    # ==========================
    # 5. å¼€å§‹è®­ç»ƒ
    # ==========================
    global_step = 0
    print("ğŸ”¥ å¼€å§‹è®­ç»ƒ...")
    # try:
    global_step = train_embedding_model(
        embedding_model=embedding_model,
        train_loader=train_loader,
        valid_loader=valid_loader,
        optimizer=optimizer,
        args=args,
        writer=writer,
        log_file=log_file,
        global_step=global_step
    )
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    # except Exception as e:
    #     print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    #     raise

    # ==========================
    # 6. ä¿å­˜æœ€ç»ˆæ¨¡å‹
    # ==========================
    
    final_save_dir.mkdir(parents=True, exist_ok=True)

    save_path = final_save_dir / "model.pt"
    torch.save(embedding_model.state_dict(), save_path)
    print(f"âœ… æœ€ç»ˆåµŒå…¥æ¨¡å‹å·²ä¿å­˜è‡³: {save_path}")
    log_file.write(f"INFO: Final model saved to {save_path}\n")

    return embedding_model, global_step